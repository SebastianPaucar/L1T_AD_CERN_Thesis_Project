{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# master Git revision: l1_anomaly_ae/dnn/end2end.py (EXPLANATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have all the code below. Let's break it down the code step by step to understand how it works in detail. Basically, this script is designed to train and evaluate DNN models with CMS L1 emulator inputs, leveraging TensorFlow, data handling, and plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "from typing import Any, Dict, List, Optional, Tuple, Union\n",
    "\n",
    "import numpy as np\n",
    "import h5py as h5\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "from utilities.configuration_classes import Config\n",
    "from utilities.utilities import set_level, set_mpl_style, patch_mpl, set_global_rand_seed, dump_full_h5, load_full_h5\n",
    "from utilities.utilities import info, warn, error, debug\n",
    "from model.losses import configure_loss\n",
    "\n",
    "from workflow.hls import hls\n",
    "\n",
    "from workflow.plot_manager import HistPlotManager, RoCPlotManager\n",
    "\n",
    "\n",
    "from workflow.train import train\n",
    "from workflow.dataloader import DataLoader\n",
    "from workflow.prepare_evaluation_object import prepare_evaluation_object\n",
    "from workflow.trim_encoder import get_trimmed_vae, generate_trimmed_vae\n",
    "from workflow.legacy_plot import legacy_plot\n",
    "\n",
    "\n",
    "def get_bits(s: str, pos: int, length: int = 4):\n",
    "    if len(s) <= 2 and s.isdigit():\n",
    "        i = int(s)\n",
    "        assert 0 <= i <= 15\n",
    "        s = bin(i)[2:].zfill(4)[::-1]\n",
    "    if len(s) != length:\n",
    "        return False\n",
    "    for c in s:\n",
    "        if c != '0' and c != '1':\n",
    "            return False\n",
    "    return s[pos] == '1'\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser(description='Train and test model')\n",
    "    parser.add_argument('--config', type=str, default='dnn/config.yml', help='Configuration file with IO and training parameters setup')\n",
    "    parser.add_argument('--run', type=str, default='all', help='what to run: train, eval, or all')\n",
    "    parser.add_argument('--verbose-level', '-v', type=str, help='verbosity level, number or name', default='INFO')\n",
    "    parser.add_argument('--force-cache-refresh', '-fr', action='store_true', help='force refresh of cache')\n",
    "    args = parser.parse_args()\n",
    "    set_level(args.verbose_level)\n",
    "\n",
    "    info(f\"Using config file from {args.config}\")\n",
    "    config = Config.from_file(args.config)\n",
    "\n",
    "    if os.path.isdir(config.output_path):\n",
    "        if config.silent_overwrite:\n",
    "            warn(f\"Output path {config.output_path} already exists. Will overwriting silently.\")\n",
    "        else:\n",
    "            input(\"Warning: output directory exists. Press Enter to continue...\")\n",
    "    else:\n",
    "        os.mkdir(config.output_path)\n",
    "\n",
    "    debug(f\"Save config file to {config.output_path + '/config.json'}\")\n",
    "    config.dump(config.output_path + '/config.json')\n",
    "\n",
    "    dataloader = DataLoader(config.data)\n",
    "\n",
    "    set_mpl_style()\n",
    "    if config.save_json_for_plots:\n",
    "        patch_mpl()\n",
    "\n",
    "    if config.global_seed is None:\n",
    "        config.global_seed = np.random.randint(0, 1000000)\n",
    "\n",
    "    info(f\"Global random seed set to {config.global_seed}\")\n",
    "    set_global_rand_seed(config.global_seed)\n",
    "\n",
    "    if args.force_cache_refresh:\n",
    "        dataloader.load(force_refresh=True)\n",
    "\n",
    "    if config.train.deterministic:\n",
    "        tf.config.experimental.enable_op_determinism()\n",
    "        warn(\"Deterministic mode is enabled. Performance may degrade.\")\n",
    "\n",
    "    if args.run == 'all' or 'train' in args.run or get_bits(args.run, 0):\n",
    "        dataset = dataloader.get_dataset()\n",
    "        scales, biases = dataset.norm_scale, dataset.norm_bias\n",
    "        with h5.File(config.output_path + '/scales.h5', 'w') as f:\n",
    "            f.create_dataset('norm_scale', data=scales)\n",
    "            f.create_dataset('norm_bias', data=biases)\n",
    "            \n",
    "            \n",
    "        configure_loss(dataset.norm_scale, dataset.norm_bias, config.data.constituents_mask)\n",
    "        train(config, dataloader.get_dataset())\n",
    "        generate_trimmed_vae(config)        \n",
    "\n",
    "    if args.run == 'all' or 'eval' in args.run or get_bits(args.run, 1):\n",
    "        dataset = dataloader.get_dataset()\n",
    "        configure_loss(dataset.norm_scale, dataset.norm_bias, config.data.constituents_mask)\n",
    "        prepare_evaluation_object(config, dataset)\n",
    "        hls_model = hls(config, do_csim=True, dataset=dataset)\n",
    "\n",
    "    if args.run == 'all' or 'plot' in args.run or get_bits(args.run, 2):\n",
    "        results = load_full_h5(config.output_path + '/results.h5')\n",
    "        hist_plot_manager = HistPlotManager(config, results)\n",
    "        roc_plot_manager = RoCPlotManager(config, results)\n",
    "        input_plot_manager = InputPlotManager(config, results)\n",
    "        roc_plot_manager.plot_eff_table()\n",
    "        hist_plot_manager.plt_hls_dist(config.hls_metric)\n",
    "        roc_plot_manager.plot_all_roc_curves(16)\n",
    "        input_plot_manager.plot_all_input_hist()\n",
    "        input_plot_manager.plot_all_input_correlation()\n",
    "\n",
    "    if args.run == 'all' or 'hls' in args.run or get_bits(args.run, 3):\n",
    "        hls_model = hls(config, do_csim=False, do_synth=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see each part of the code:\n",
    "### **Import Statements**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "from typing import Any, Dict, List, Optional, Tuple, Union\n",
    "\n",
    "import numpy as np\n",
    "import h5py as h5\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `argparse`: Handles command-line arguments. This allows the script to be more flexible and cofigurable without the need to modify the code.\n",
    "* `os`: Provides a way to use operating system dependent functionality. We can interact with the Operative System.\n",
    "* `typing`: Provides type hints.\n",
    "* `numpy` (np): Numerical operations (numerical arrays).\n",
    "* `h5py` (h5): Interacts with HDF5 files. It imports HDF5 to handle data storage files in HDF5 format.\n",
    "* `os.environ['TF_CPP_MIN_LOG_LEVEL']`: Sets TensorFlow logging level to minimize unnecessary logs and shows only eror messages (level 3).\n",
    "* `tensorflow` (tf): Core library for building and training models.\n",
    "* `tensorflow.keras`: High-level API for building neural networks.\n",
    "\n",
    "### **GPU Configuration**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `tf.config.experimental.list_physical_devices('GPU')`: Lists available GPUs.\n",
    "* `tf.config.experimental.set_memory_growth(gpu, True)`: Configures TensorFlow to use GPU memory as needed instead of allocating all at once."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Matplotlib for Plotting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `matplotlib.pylot`: Library for creating static, animated, and interactive visualizations.\n",
    "\n",
    "### **Import Custom Utilities and Modules**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities.configuration_classes import Config\n",
    "from utilities.utilities import set_level, set_mpl_style, patch_mpl, set_global_rand_seed, dump_full_h5, load_full_h5\n",
    "from utilities.utilities import info, warn, error, debug\n",
    "from model.losses import configure_loss\n",
    "\n",
    "from workflow.hls import hls\n",
    "\n",
    "from workflow.plot_manager import HistPlotManager, RoCPlotManager\n",
    "\n",
    "from workflow.train import train\n",
    "from workflow.dataloader import DataLoader\n",
    "from workflow.prepare_evaluation_object import prepare_evaluation_object\n",
    "from workflow.trim_encoder import get_trimmed_vae, generate_trimmed_vae\n",
    "from workflow.legacy_plot import legacy_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In that code block, `utilities` and `workflow` are custom modules created specifically for this AD project (they are not standard Python libraries. We can see them in `l1_anomaly_ae/dnn`).\n",
    "\n",
    "* `Config`: Handles configuration settings.\n",
    "* `set_level, set_mpl_style, patch_mpl, set_global_rand_seed, dump_full_h5, load_full_h5`: Various utility functions for logging, setting styles, seeding, and handling HDF5 files (set up the  log verbosity level, the matplotlib style for graphics and additional patches; set a global seed for random number generation; saves data on a HDF5 file, and load data from a HDF5 file).\n",
    "* `info, warn, error, debug`: Logging functions.\n",
    "* `configure_loss`: Configures the loss function for the model.\n",
    "* `hls`: High-Level Synthesis related functionality.\n",
    "* `HistPlotManager, RoCPlotManager`: Manages plotting of histograms and ROC curves.\n",
    "* `train`: Function to train the model.\n",
    "* `DataLoader`: Handles loading and preparing data.\n",
    "* `prepare_evaluation_object`: Prepares the object for evaluation.\n",
    "*`get_trimmed_vae, generate_trimmed_vae`: Functions to handle trimmed VAE models.\n",
    "* `legacy_plot`: Handles legacy plotting.\n",
    "\n",
    "### **Bit Extraction Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bits(s: str, pos: int, length: int = 4):\n",
    "    if len(s) <= 2 and s.isdigit():\n",
    "        i = int(s)\n",
    "        assert 0 <= i <= 15\n",
    "        s = bin(i)[2:].zfill(4)[::-1]\n",
    "    if len(s) != length:\n",
    "        return False\n",
    "    for c in s:\n",
    "        if c != '0' and c != '1':\n",
    "            return False\n",
    "    return s[pos] == '1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `get_bits`: Extracts bits from a binary string. Ensures the string is of correct length and composed of 0s and 1s. Used to check specific positions (and to determine whether this specific bit is on, i.e, 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Main Script Execution**\n",
    "\n",
    "This code block checks if the script is running directly (not imported as a module), and if so, executes the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser(description='Train and test model')\n",
    "    parser.add_argument('--config', type=str, default='dnn/config.yml', help='Configuration file with IO and training parameters setup')\n",
    "    parser.add_argument('--run', type=str, default='all', help='what to run: train, eval, or all')\n",
    "    parser.add_argument('--verbose-level', '-v', type=str, help='verbosity level, number or name', default='INFO')\n",
    "    parser.add_argument('--force-cache-refresh', '-fr', action='store_true', help='force refresh of cache')\n",
    "    args = parser.parse_args()\n",
    "    set_level(args.verbose_level)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `parser = argparse.ArgumentParser(...)`: Creates a ArgumentParser object with a description of the script.\n",
    "* `parser.add_argument(...)`: Defined the arguments that the script can accept:\n",
    "    * `--config`: Configuration archives route.\n",
    "    * `--run`: Specifies the operation to do (train, eval, all).\n",
    "    * `--verbose-level` (-v): log output verbosity level.\n",
    "    * `--force-cache-refresh` (-fr): Force cache update if necessary.\n",
    "* `args = parser.parse_args()`: Analize the command line arguments and save them in `args`.\n",
    "* `set_level(args.verbose_level)`: Sets the logging verbosity level.\n",
    "\n",
    "<span style=\"color: red;\"> Key question: What is verbosity? Does this main script work by reading what you type in the terminal? </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Configuration and Output Directory Handling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    set_level(args.verbose_level)\n",
    "    info(f\"Using config file from {args.config}\")\n",
    "    config = Config.from_file(args.config)\n",
    "\n",
    "    if os.path.isdir(config.output_path):\n",
    "        if config.silent_overwrite:\n",
    "            warn(f\"Output path {config.output_path} already exists. Will overwriting silently.\")\n",
    "        else:\n",
    "            input(\"Warning: output directory exists. Press Enter to continue...\")\n",
    "    else:\n",
    "        os.mkdir(config.output_path)\n",
    "\n",
    "    debug(f\"Save config file to {config.output_path + '/config.json'}\")\n",
    "    config.dump(config.output_path + '/config.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main purpose of this code block is to guarantee that the program has a secure place to storage its output files. If the output directory already exists, the program take the user configuration `silent_overwrite`. If it doesn't exist, the program creates the directory to ensure that can write the necessary files without errors.\n",
    "\n",
    "* `Config.from_file`: Loads configuration from the specified YAML file.\n",
    "* **Checks if output directory exists**: If it exists, warns the user (unless silent overwrite is enabled).\n",
    "* Creates output directory if it doesn't exist.\n",
    "* `config.dump`: Saves the configuration to a JSON file in the output directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Data Loading and Plot Settings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    dataloader = DataLoader(config.data)\n",
    "\n",
    "    set_mpl_style()\n",
    "    if config.save_json_for_plots:\n",
    "        patch_mpl()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `DataLoader(config.data)`: Initializes the data loader with configuration data. `dataloader` is an DataLoader object for handling data. `DataLoader` is a class that is responsible for loading (andre possibly preprocessing) the data necessary for training and evaluating the model. `config.data` is a configuration parameter that contains information about where the data is located, how it should be charged and another revelant configuration.\n",
    "* `set_mpl_style()`: Sets the Matplotlib style (consistent and visually appealing).\n",
    "* `patch_mpl()`: Patches Matplotlib if saving JSON for plots is enabled (applies necessary configuration to Matplotlib to support JSON functionality)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Global Seed and Cache Handling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    if config.global_seed is None:\n",
    "        config.global_seed = np.random.randint(0, 1000000)\n",
    "\n",
    "    info(f\"Global random seed set to {config.global_seed}\")\n",
    "    set_global_rand_seed(config.global_seed)\n",
    "\n",
    "    if args.force_cache_refresh:\n",
    "        dataloader.load(force_refresh=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Sets a random global seed if not provided. `if config.global_seed is None` checks if the global seed (`global_seed`) is defined. In the context of computational algorithms, the random number generators are usually pseudorandom number generators (PRNG), because the generated number sequences are determined by an initial seed. The seed acts as a starting point for the algorithm that generates the sequence.\n",
    "* `set_global_rand_seed`: Sets the global random seed for reproducibility. `set_global_rand_seed(config.global_seed)` is responsible to apply the global seed to random number generators of used libraries as NumPy and TensorFlow. By **reproducibility** we mean the capablity to obtain the same results from an experiment each time it is repeated under the same conditions.\n",
    "* Forces data cache refresh if specified."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Deterministic Mode and Workflow Steps**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In ML and data processing applications, reproducibility and determinism are important to ensure that experiments and results are consistent between run. This is relevant when using random operations or operations that may depend on multiple hardware factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    if config.train.deterministic:\n",
    "        tf.config.experimental.enable_op_determinism()\n",
    "        warn(\"Deterministic mode is enabled. Performance may degrade.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Enables deterministic mode for reproducibility at the potential cost of performance. Sets TensorFlow for deterministic mode if it is specified in the configuration.\n",
    "* `config.train.deterministic` indicates if the training should be realized on deterministic mode (it is a `boolean` flag established in the `.yml` file).\n",
    "* `tf.config.experimental.enable_op_determinism()`: This function belongs to TensorFlow library and is used to turn on the deterministic mode for operations. With this, TensorFlow attempts to ensure that all operations are executed so that the results are the same each run (i.e, if the program is run several times under the same conditions, exactly the same results will be obtained), regardless of factors such as hardware or parallelization.\n",
    "* `warn(\"Deterministic mode is enabled. Performance may degrade.\")`: When you enable deterministic mode, ther may be a degradation in performance. This is because some hardware-dependent optimizations (such as parallelization on GPUs) may not support full determinisim, which can cause slower operations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Training Step**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    if args.run == 'all' or 'train' in args.run or get_bits(args.run, 0):\n",
    "        dataset = dataloader.get_dataset()\n",
    "        scales, biases = dataset.norm_scale, dataset.norm_bias\n",
    "        with h5.File(config.output_path + '/scales.h5', 'w') as f:\n",
    "            f.create_dataset('norm_scale', data=scales)\n",
    "            f.create_dataset('norm_bias', data=biases)\n",
    "            \n",
    "        configure_loss(dataset.norm_scale, dataset.norm_bias, config.data.constituents_mask)\n",
    "        train(config, dataloader.get_dataset())\n",
    "        generate_trimmed_vae(config)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Runs if `all`, `train`, or specific bit is set (that is, tells the `get_bits` function to verified if the first bit -position 0- in `args.run` is active).\n",
    "* Loads (using `dataloader`) and normalizes (`norm_scale` and `norm_bias` are normalized data from `dataset`) dataset, save the scales and biases.\n",
    "* Saves normalized scales and biases to an HDF5 file specified by `config.output_path`. That is useful for saving and loading these normalizations in future runs of the program.\n",
    "* Configures loss function according to the normalized scales and the constituent mask defined in `config`.\n",
    "* Trains the model using the configuration provided and the dataset obtained from `dataloader`.\n",
    "* Generates a trimmed VAE model according `config`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Evaluation Step**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    if args.run == 'all' or 'eval' in args.run or get_bits(args.run, 1):\n",
    "        dataset = dataloader.get_dataset()\n",
    "        configure_loss(dataset.norm_scale, dataset.norm_bias, config.data.constituents_mask)\n",
    "        prepare_evaluation_object(config, dataset)\n",
    "        hls_model = hls(config, do_csim=True, dataset=dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in the previous code. This code block runs if `all`, `eval` or specific bit (the second bit, i.e, the -position 1- bit) is set; lodas dataset and configures loss function (using the same loss metrics as the training, ensuring consistency in the evaluation). However, we can see additionaly that:\n",
    "* `prepare_evaluation_object`: Prepares the object to carry out the model evaluation (it may includes additional metrics, preparing specific data for evaluation, etc.).\n",
    "* `hls`: Defined in `workflow/hls.py`, it is used to perform a HLS simulation. HLS is a process that transforms **High-Level** hardware descriptions into specific hardware. `do_csim=True` indicates that a behavioral simulation should be done. This part of the code prepares the object of evaluation and executes the workflow HLS.\n",
    "* This evaluation step includes the exuction of a HLS workflow with **co-simulation** for validating and evaluating the model implementation in hardware. The **co-simulation** is a process which simulations from different domains (e.g. software and hardware) are combined to validate that both work correctly together. In HLS, co-simulation verifies that the HL model (usually wirtten in a language such as C/C++) behaves correctly and consistently when synsthesized in hardware. This ensure that HLS hardware design is correct and meets the HL model functionality expectatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Plotting Step**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the functions that are called to visualize the model's performanca and data (note that the graphics are also generated if the third bit -position 2- is active):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    if args.run == 'all' or 'plot' in args.run or get_bits(args.run, 2):\n",
    "        results = load_full_h5(config.output_path + '/results.h5')\n",
    "        hist_plot_manager = HistPlotManager(config, results)\n",
    "        roc_plot_manager = RoCPlotManager(config, results)\n",
    "        input_plot_manager = InputPlotManager(config, results)\n",
    "        roc_plot_manager.plot_eff_table()\n",
    "        hist_plot_manager.plt_hls_dist(config.hls_metric)\n",
    "        roc_plot_manager.plot_all_roc_curves(16)\n",
    "        input_plot_manager.plot_all_input_hist()\n",
    "        input_plot_manager.plot_all_input_correlation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `load_full_h5()`: Loads the evaluation results from an HDF5 file.\n",
    "* `HistPlotManager();RoCPlotManager();InputPlotManager()`: Initializes plot managers for histograms, ROC curves, and input data.\n",
    "* `plot_eff_table()`: Plots an efficiency table.\n",
    "* `plt_hls_dist()`: Plots de HLS metric distribution.\n",
    "* `plot_all_roc_curves(16)`: Plots all ROC curves.\n",
    "* `plot_all_input_hist()`: Plots histograms of all input features.\n",
    "* `plot_all_input_correlation()`: Plots correlation between all input features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **HLS (High-Level Synsthesis) Step**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that this code block will also run if the fourth bit -position 3- is active. This method could be used to active or desactive specific code parts based on a binary scheme. If `args.run` is a binary number represented by a string, this conditional will see the fourth bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    if args.run == 'all' or 'hls' in args.run or get_bits(args.run, 3):\n",
    "        hls_model = hls(config, do_csim=False, do_synth=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code block is responsible for initializing the HLS based on the provided configurations. The conditional indicates that this process should be performed if the arguments provided to the program (`args.run`) allow it.\n",
    "\n",
    "* Runs if `all`, `hls` or specific bit is set.\n",
    "* `hls_model`: Generates the HLS model with synthesis (no co-simulation). Remember that HLS is a process that converts high-level descriptions of algorithms in low-level hardware (e.g. Verilog or VDHL).\n",
    "* `do_csim=False`: Indicates that a behavioral simulation (C simulation) should not be performed. This type of simulation is typically used to validate the functionality of the algorithm before the synsthesis.\n",
    "* `do_synth=True`: Indicates that the synthesis should be performed. Synthesis transforms the high level code into a hardware description, which is a key step for integrated circuits design.\n",
    "\n",
    "By not performing the behavior simulation but doing the synthesis, the previous validation is skipped and we proceed directly to the generation of the hardware description. This part of the workflow is crucial for projects that involve designing hardware from high-level descriptions, allowing the creation of efficient implementations on FPGA or ASIC."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
